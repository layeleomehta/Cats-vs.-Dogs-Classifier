{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3002 images loaded\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = \"./datasets/catsvsdogs/images/\"\n",
    "\n",
    "file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "print(str(len(file_names)) + ' images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test Data Extraction Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Organize dataset: extracting 1000 images for training data and 500 for test set\n",
    "dog_count = 0\n",
    "cat_count = 0\n",
    "training_size = 1000\n",
    "test_size = 500\n",
    "training_images = []\n",
    "training_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "size = 150\n",
    "dog_dir_train = \"./datasets/catsvsdogs/train/dogs/\"\n",
    "cat_dir_train = \"./datasets/catsvsdogs/train/cats/\"\n",
    "dog_dir_val = \"./datasets/catsvsdogs/validation/dogs/\"\n",
    "cat_dir_val = \"./datasets/catsvsdogs/validation/cats/\"\n",
    "\n",
    "def make_dir(directory):\n",
    "        if os.path.exists(directory):\n",
    "            shutil.rmtree(directory)\n",
    "        os.makedirs(directory)\n",
    "\n",
    "make_dir(dog_dir_train)\n",
    "make_dir(cat_dir_train)\n",
    "make_dir(dog_dir_val)\n",
    "make_dir(cat_dir_val)\n",
    "\n",
    "def getZeros(number):\n",
    "    if(number > 10 and number < 100):\n",
    "        return \"0\"\n",
    "    if(number < 10):\n",
    "        return \"00\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "for i, file in enumerate(file_names):\n",
    "    \n",
    "    if file_names[i][0] == \"d\":\n",
    "        dog_count += 1\n",
    "        image = cv2.imread(mypath+file)\n",
    "        image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "        if dog_count <= training_size:\n",
    "            training_images.append(image)\n",
    "            training_labels.append(1)\n",
    "            zeros = getZeros(dog_count)\n",
    "            cv2.imwrite(dog_dir_train + \"dog\" + str(zeros) + str(dog_count) + \".jpg\", image)\n",
    "        if dog_count > training_size and dog_count <= training_size+test_size:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(1)\n",
    "            zeros = getZeros(dog_count-1000)\n",
    "            cv2.imwrite(dog_dir_val + \"dog\" + str(zeros) + str(dog_count-1000) + \".jpg\", image)\n",
    "            \n",
    "    if file_names[i][0] == \"c\":\n",
    "        cat_count += 1\n",
    "        image = cv2.imread(mypath+file)\n",
    "        image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "        if cat_count <= training_size:\n",
    "            training_images.append(image)\n",
    "            training_labels.append(0)\n",
    "            zeros = getZeros(cat_count)\n",
    "            cv2.imwrite(cat_dir_train + \"cat\" + str(zeros) + str(cat_count) + \".jpg\", image)\n",
    "        if cat_count > training_size and cat_count <= training_size+test_size:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(0)\n",
    "            zeros = getZeros(cat_count-1000)\n",
    "            cv2.imwrite(cat_dir_val + \"cat\" + str(zeros) + str(cat_count-1000) + \".jpg\", image)\n",
    "\n",
    "    if dog_count == training_size+test_size and cat_count == training_size+test_size:\n",
    "        break\n",
    "\n",
    "print(\"Training and Test Data Extraction Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy's savez function to store loaded data as NPZ files\n",
    "np.savez('cats_vs_dogs_training_data.npz', np.array(training_images))\n",
    "np.savez('cats_vs_dogs_training_labels.npz', np.array(training_labels))\n",
    "np.savez('cats_vs_dogs_test_data.npz', np.array(test_images))\n",
    "np.savez('cats_vs_dogs_test_labels.npz', np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading function definition\n",
    "import numpy as np\n",
    "\n",
    "def load_data_training_and_test(datasetname):\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_training_data.npz\")\n",
    "    train = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_training_labels.npz\")\n",
    "    train_labels = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_data.npz\")\n",
    "    test = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_labels.npz\")\n",
    "    test_labels = npzfile['arr_0']\n",
    "\n",
    "    return (train, train_labels), (test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Dog\n",
      "2 - Dog\n",
      "3 - Dog\n",
      "4 - Cat\n",
      "5 - Dog\n",
      "6 - Cat\n",
      "7 - Dog\n",
      "8 - Cat\n",
      "9 - Cat\n",
      "10 - Cat\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    random = np.random.randint(0, len(training_images))\n",
    "    cv2.imshow(\"image_\"+str(i), training_images[random])\n",
    "    if training_labels[random] == 0:\n",
    "        print(str(i) + \" - Cat\")\n",
    "    else:\n",
    "        print(str(i)+ \" - Dog\")\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 150, 150, 3)\n",
      "(2000, 1)\n",
      "(1000, 150, 150, 3)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data_training_and_test(\"cats_vs_dogs\")\n",
    "\n",
    "# Reshaping label data to fit keras input shape\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "# Change image type to float32 data type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing data by changing the range from (0 to 255) to (0 to 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "import scipy\n",
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 1000\n",
    "batch_size = 16\n",
    "epochs = 25\n",
    "\n",
    "train_data_dir = './datasets/catsvsdogs/train'\n",
    "validation_data_dir = './datasets/catsvsdogs/validation'\n",
    "\n",
    "# Creating Image Data Generator for our test data\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    # used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "    rescale = 1./255)\n",
    "\n",
    "# Creating Image Data Generator for our training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,              # normalize pixel values to [0,1]\n",
    "      rotation_range = 30,           # randomly applies rotations\n",
    "      width_shift_range = 0.3,       # randomly applies width shifting\n",
    "      height_shift_range = 0.3,      # randomly applies height shifting\n",
    "      horizontal_flip = True,        # randonly flips the image\n",
    "      fill_mode = 'nearest')         # uses the fill mode nearest to fill gaps created by the above\n",
    "\n",
    "# Specify criteria abouttraining data, such as the directory, image size, batch size and type \n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'binary',\n",
    "        shuffle = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\layea\\anaconda3\\envs\\jupyter-env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.7236 - accuracy: 0.5295 - val_loss: 0.5759 - val_accuracy: 0.5927\n",
      "Epoch 2/25\n",
      "125/125 [==============================] - 103s 826ms/step - loss: 0.6801 - accuracy: 0.5640 - val_loss: 0.6120 - val_accuracy: 0.5650\n",
      "Epoch 3/25\n",
      "125/125 [==============================] - 100s 801ms/step - loss: 0.6677 - accuracy: 0.6030 - val_loss: 0.7121 - val_accuracy: 0.6514\n",
      "Epoch 4/25\n",
      "125/125 [==============================] - 103s 824ms/step - loss: 0.6669 - accuracy: 0.6005 - val_loss: 0.7392 - val_accuracy: 0.6606\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - 113s 902ms/step - loss: 0.6466 - accuracy: 0.6395 - val_loss: 0.6179 - val_accuracy: 0.6890\n",
      "Epoch 6/25\n",
      "125/125 [==============================] - 110s 878ms/step - loss: 0.6468 - accuracy: 0.6390 - val_loss: 0.7188 - val_accuracy: 0.6911\n",
      "Epoch 7/25\n",
      "125/125 [==============================] - 92s 740ms/step - loss: 0.6436 - accuracy: 0.6435 - val_loss: 0.4129 - val_accuracy: 0.6677\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - 110s 879ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.3857 - val_accuracy: 0.7083\n",
      "Epoch 9/25\n",
      "125/125 [==============================] - 99s 796ms/step - loss: 0.6323 - accuracy: 0.6575 - val_loss: 0.5232 - val_accuracy: 0.6992\n",
      "Epoch 10/25\n",
      "125/125 [==============================] - 104s 830ms/step - loss: 0.6131 - accuracy: 0.6705 - val_loss: 0.3843 - val_accuracy: 0.7154\n",
      "Epoch 11/25\n",
      "125/125 [==============================] - 99s 793ms/step - loss: 0.6125 - accuracy: 0.6515 - val_loss: 0.6262 - val_accuracy: 0.7053\n",
      "Epoch 12/25\n",
      "125/125 [==============================] - 104s 834ms/step - loss: 0.6165 - accuracy: 0.6820 - val_loss: 0.2620 - val_accuracy: 0.6677\n",
      "Epoch 13/25\n",
      "125/125 [==============================] - 104s 828ms/step - loss: 0.6220 - accuracy: 0.6645 - val_loss: 0.3944 - val_accuracy: 0.7215\n",
      "Epoch 14/25\n",
      "125/125 [==============================] - 100s 797ms/step - loss: 0.6270 - accuracy: 0.6635 - val_loss: 0.4631 - val_accuracy: 0.7287\n",
      "Epoch 15/25\n",
      "125/125 [==============================] - 104s 831ms/step - loss: 0.6103 - accuracy: 0.6840 - val_loss: 0.5969 - val_accuracy: 0.6778\n",
      "Epoch 16/25\n",
      "125/125 [==============================] - 110s 880ms/step - loss: 0.6182 - accuracy: 0.6765 - val_loss: 0.6014 - val_accuracy: 0.7337\n",
      "Epoch 17/25\n",
      "125/125 [==============================] - 129s 1s/step - loss: 0.5999 - accuracy: 0.6935 - val_loss: 0.3800 - val_accuracy: 0.6931\n",
      "Epoch 18/25\n",
      "125/125 [==============================] - 117s 936ms/step - loss: 0.6082 - accuracy: 0.6835 - val_loss: 0.3554 - val_accuracy: 0.7154\n",
      "Epoch 19/25\n",
      "125/125 [==============================] - 116s 931ms/step - loss: 0.6250 - accuracy: 0.6830 - val_loss: 0.6497 - val_accuracy: 0.7358\n",
      "Epoch 20/25\n",
      "125/125 [==============================] - 120s 960ms/step - loss: 0.6154 - accuracy: 0.6895 - val_loss: 0.3470 - val_accuracy: 0.7480\n",
      "Epoch 21/25\n",
      "125/125 [==============================] - 108s 868ms/step - loss: 0.6033 - accuracy: 0.6830 - val_loss: 0.2089 - val_accuracy: 0.6961\n",
      "Epoch 22/25\n",
      "125/125 [==============================] - 109s 871ms/step - loss: 0.5947 - accuracy: 0.6975 - val_loss: 0.2441 - val_accuracy: 0.6392\n",
      "Epoch 23/25\n",
      "125/125 [==============================] - 125s 998ms/step - loss: 0.6013 - accuracy: 0.6975 - val_loss: 0.6623 - val_accuracy: 0.7124\n",
      "Epoch 24/25\n",
      "125/125 [==============================] - 122s 975ms/step - loss: 0.5993 - accuracy: 0.6920 - val_loss: 0.2291 - val_accuracy: 0.7175\n",
      "Epoch 25/25\n",
      "125/125 [==============================] - 124s 990ms/step - loss: 0.6043 - accuracy: 0.6855 - val_loss: 0.7917 - val_accuracy: 0.7033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Cats-vs-Dogs-Classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('./Cats-vs-Dogs-Classifier.h5')\n",
    "\n",
    "def draw_test(name, pred, input_im):\n",
    "    BLACK = [0,0,0]\n",
    "    if pred == \"[0]\":\n",
    "        pred = \"cat\"\n",
    "    if pred == \"[1]\":\n",
    "        pred = \"dog\"\n",
    "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0] ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    #expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image, str(pred), (252, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    rand = np.random.randint(0,len(x_test))\n",
    "    input_im = x_test[rand]\n",
    "\n",
    "    imageL = cv2.resize(input_im, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Test Image\", imageL)\n",
    "\n",
    "    input_im = input_im.reshape(1,150,150,3) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "\n",
    "    draw_test(\"Prediction\", res, imageL) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter-env] *",
   "language": "python",
   "name": "conda-env-jupyter-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
